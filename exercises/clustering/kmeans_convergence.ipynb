{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lingchm/datascience/blob/master/exercises/socially_distanced_robots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVWkxKm9TYyT"
   },
   "source": [
    "# KMeans\n",
    "\n",
    "*kmeans*, *clustering*\n",
    "\n",
    "**Problem**\n",
    "\n",
    "Given $m$ data points $\\{x\\}_{i=1}^m$, we want to cluster them into $k$ groups based on similarity. \n",
    "\n",
    "**Method**\n",
    "\n",
    "K-means is a clustering algorithm that groups data points into $k$ clusters by minimizing the distortion function over $\\{r^{ij}, \\mu^j\\}$:\n",
    "$$J = \\sum_{i=1}^m \\sum_{j=1}^k r^{ij} || x^i-\\mu^j|| ^2,$$\n",
    "where $r^{ij} = 1$ if $x^i$ belongs to the j-th cluster and $r^{ij} = 0$ otherwise. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means using Euclidean distance\n",
    "\n",
    "Using Euclidean distance, the center of the clusters have solution\n",
    "\n",
    "$$\\mu^j = \\frac{\\sum_{i=1}^m r^{ij}x^i}{\\sum_{i=1}^m r^{ij}}$$\n",
    "\n",
    "*Proof*. To minimize the distortion function, we compute the derivative:\n",
    "$\n",
    "\\begin{align} \n",
    "\\frac{dJ}{d\\mu} &= \\frac{d}{d\\mu} ( \\sum_{i=1}^m \\sum_{j=1}^k r^{ij} || x^i-\\mu^j||) \n",
    "                = \\sum_{i=1}^m \\sum_{j=1}^k r^{ij} \\frac{d}{d\\mu}|| x^i-\\mu^j|| \\\\ \n",
    "                &= \\sum_{i=1}^m \\sum_{j=1}^k -2r^{ij} (x^i - \\mu^j) \n",
    "                = \\sum_{i=1}^m \\sum_{j=1}^k -2r^{ij} (x^i - \\mu^j) \\\\\n",
    "                &= \\sum_{i=1}^m \\sum_{j=1}^k 2r^{ij} \\mu^j - \\sum_{i=1}^m \\sum_{j=1}^k 2r^{ij}x^i = 0 \\\\ \n",
    "                &\\Rightarrow \\sum_{i=1}^m \\sum_{j=1}^k 2r^{ij} \\mu^j = \\sum_{i=1}^m \\sum_{j=1}^k 2r^{ij}x^i \\\\\n",
    "                &\\Rightarrow \\mu^j = \\frac{\\sum_{i=1}^m r^{ij}x^i}{\\sum_{i=1}^m r^{ij}}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means using Mahalanobis distance\n",
    "\n",
    "Mahalanobis distance is another popular distance measure: $d(x,y) = (x-y)^T \\Sigma (x-y)$. In Mahalanobis distance, the distance measure is computed after vectors are \"transformed\" taking into account the variance and covariance amongst the variables.\n",
    "\n",
    "We show that the centroids in this case are still the same as (2).\n",
    "\n",
    "*Proof*. The K-means algorithms' distortion function under Mahalanobis distance becomes\n",
    "$$J = \\sum_{i=1}^m \\sum_{j=1}^k r^{ij} (x^i-\\mu^j)^T \\Sigma (x^i-\\mu^j),$$\n",
    "where $\\sum$ is the covariance matrix.\n",
    "\n",
    "To minimize the distortion function, we compute the derivative:\n",
    "$\n",
    "\\begin{align} \n",
    "\\frac{dJ}{d\\mu} &= \\frac{d}{d\\mu} (\\sum_{i=1}^m \\sum_{j=1}^k r^{ij} (x^i-\\mu^j)^T \\sum (x^i-\\mu^j)) \n",
    "                = \\sum_{i=1}^m \\sum_{j=1}^k r^{ij} \\frac{d}{d\\mu} ((x^i-\\mu^j)^T \\sum (x^i-\\mu^j)) \\\\ \n",
    "                &= \\sum_{i=1}^m \\sum_{j=1}^k -2r^{ij} \\sum (x^i-\\mu^j) \n",
    "                = \\sum_{i=1}^m \\sum_{j=1}^k 2r^{ij} \\sum \\mu^j - \\sum_{i=1}^m \\sum_{j=1}^k 2r^{ij} \\sum x^i = 0 \\\\ \n",
    "                &\\Rightarrow \\sum_{i=1}^m \\sum_{j=1}^k r^{ij} \\mu^j = \\sum_{i=1}^m \\sum_{j=1}^k r^{ij}x^i \\\\\n",
    "                &\\Rightarrow \\mu^j = \\frac{\\sum_{i=1}^m r^{ij}x^i}{\\sum_{i=1}^m r^{ij}}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "Under squared Euclidean distance, the assignment function is:\n",
    "$$\\pi(i) = \\arg \\min_{j=1 \\dots k} ||x^i - \\mu^j||^2$$\n",
    "\n",
    "Under Mahalanobis distance, the assignment function is:\n",
    "$$\\pi(i) = \\arg \\min_{j=1 \\dots k} (x^i - \\mu^j)^T \\Sigma (x^i - \\mu^j)$$\n",
    "\n",
    "The assignment function has changed because the distance function used to find the closest cluster has changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLOgyIRpiJIV"
   },
   "source": [
    "## Convergence of K-means\n",
    "\n",
    "We will prove that the K-means algorithm converges to a local optimum in finite steps.\n",
    "\n",
    "Let $J = \\sum_{i=1}^m \\sum_{j=1}^k r^{ij} || x^i-\\mu^j|| ^2, r^{i, \\pi(i)} = 1$ be the cost function. K-means algorithm works to minimize $J$ at each iteration and we know that:\n",
    "\n",
    "* For each iteration, $J$ is going to decrease:\n",
    " * cluster assignment is decreasing the distorsion function by $\\pi(i) = \\arg \\min ||x^i - c^j||^2$\n",
    " * center adjustment is decreasing the distorsion function by $c^j = \\arg \\min \\sum ||x^i - c||^2$\n",
    "* $J \\geq 0$ since it is the sum of squared distances\n",
    "* Given $m$ data points and $k$ clusters, there are at most $k^m$ ways to assign data points to clusters (each data point has $k$ choices). Therefore, the algorithm is guaranteed to terminate \n",
    "\n",
    "By knowing that the algorithm will terminate, is decreasing the distorsion function, and that the distorsion function is always greater than zero, we can conclude that the algorithm converges to a local optimum in finite steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of K-means using Manhattan distance\n",
    "\n",
    "Given the following 5 point configuration, we will compute K-means by hand using Manhattan distance.\n",
    "![ex 2.13](data/points.png)\n",
    "\n",
    "Initialization:\n",
    "\n",
    "          k = 2, m = 5\n",
    "          cB = (2, 1), cA = (-3, -1)\n",
    "\n",
    "Iteration 1:\n",
    "\n",
    "* Cluster assigment\n",
    "\n",
    "        m1 = (2, 2)    d(m1, cB)= 1  d(m1, cA) = 8 -> pi(1) = B\n",
    "        m2 = (-1, 1)   d(m2, cB)= 3  d(m1, cA) = 4 -> pi(2) = B\n",
    "        m3 = (3, 1)    d(m2, cB)= 1  d(m1, cA) = 8 -> pi(3) = B\n",
    "        m4 = (0, -1)   d(m2, cB)= 4  d(m1, cA) = 3 -> pi(4) = A\n",
    "        m5 = (-2, -2)  d(m2, cB)= 7  d(m1, cA) = 2 -> pi(5) = A\n",
    "        J = 1 + 3 + 1 + 3 + 2 = 10\n",
    "        \n",
    "* Center adjustment:\n",
    "\n",
    "        A: \n",
    "        arg min Jx = |0-cAx| + |-2-cAx| \n",
    "        arg min Jy = |-1-cAy| + |-2-cAy|  \n",
    "        => cA = (-3, -1)\n",
    "\n",
    "        B: \n",
    "        arg min Jx = |2-cBx| + |-1-cBx| + |3-cBx| \n",
    "        arg min Jy = |2-cBy| + |1-cBy| + |1-cBy| \n",
    "        => cB = (2, 1)\n",
    "        \n",
    "Iteration 2:\n",
    "\n",
    "* Cluster assigment\n",
    "\n",
    "        m1 = (2, 2)    d(m1, cB)= 1  d(m1, cA) = 6 -> pi(1) = B\n",
    "        m2 = (-1, 1)   d(m2, cB)= 3  d(m1, cA) = 2 -> pi(2) = A\n",
    "        m3 = (3, 1)    d(m2, cB)= 1  d(m1, cA) = 6 -> pi(3) = B\n",
    "        m4 = (0, -1)   d(m2, cB)= 4  d(m1, cA) = 1 -> pi(4) = A\n",
    "        m5 = (-2, -2)  d(m2, cB)= 7  d(m1, cA) = 2 -> pi(5) = A\n",
    "        J = 1 + 2 + 1 + 1 + 2 = 7\n",
    "        \n",
    "* Center adjustment:\n",
    "\n",
    "        A: \n",
    "        arg min Jx = |-1-cAx| + |0-cAx| + |-2-cAx| \n",
    "        arg min Jy = |1-cAy| + |-1-cAy| + |-2-cAy|  \n",
    "        => cA = (-1, -1)\n",
    "        B: \n",
    "        arg min Jx = |2-cBx| + |3-cBx|  \n",
    "        arg min Jy = |2-cBy| + |1-cBy|\n",
    "        => cB = (2, 1)\n",
    "        \n",
    "        \n",
    "Iteration 3:\n",
    "\n",
    "* Cluster assigment\n",
    "\n",
    "        m1 = (2, 2)    d(m1, cB)= 1  d(m1, cA) = 6 -> pi(1) = B\n",
    "        m2 = (-1, 1)   d(m2, cB)= 4  d(m1, cA) = 2 -> pi(2) = A\n",
    "        m3 = (3, 1)    d(m2, cB)= 1  d(m1, cA) = 6 -> pi(3) = B\n",
    "        m4 = (0, -1)   d(m2, cB)= 5  d(m1, cA) = 1 -> pi(4) = A\n",
    "        m5 = (-2, -2)  d(m2, cB)= 8  d(m1, cA) = 2 -> pi(5) = A\n",
    "        J = 1 + 2 + 1 + 1 + 2 = 7\n",
    "        \n",
    "Since there is no improvement of $J$, the algorithm terminated at iteration 2. The final cluster assignment and location of the centers are:\n",
    "    \n",
    "        pi(1) = B\n",
    "        pi(2) = A\n",
    "        pi(3) = B\n",
    "        pi(4) = A\n",
    "        pi(5) = A\n",
    "        cA = (-1, -1)\n",
    "        cB = (2, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOTOc1U71AUuA5lNSIVuRuz",
   "include_colab_link": true,
   "name": "socially_distanced_robots.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
