{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lingchm/datascience_notes/blob/master/dl_tensorflow/advanced_cv/L4_Simple_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmANPR2jhCR6"
      },
      "source": [
        "# Simple Object Detection in Tensorflow\n",
        "\n",
        "This lab will walk you through how to use object detection models available in [Tensorflow Hub](https://www.tensorflow.org/hub). In the following sections, you will:\n",
        "\n",
        "* explore the Tensorflow Hub for object detection models\n",
        "* load the models in your workspace\n",
        "* preprocess an image for inference \n",
        "* run inference on the models and inspect the output\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install this package to use Colab's GPU for training\n",
        "!apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6"
      ],
      "metadata": {
        "id": "9Kom3HDMyxJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc6db0f-776f-44cf-cb83-c19a63a09671"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 18 not upgraded.\n",
            "Need to get 420 MB of archives.\n",
            "After this operation, 3,369 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.4.1.50-1+cuda11.6 [420 MB]\n",
            "Fetched 420 MB in 7s (61.3 MB/s)\n",
            "(Reading database ... 159447 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
            "(Reading database ... 159425 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.4.1.50-1+cuda11.6_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.4.1.50-1+cuda11.6) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.4.1.50-1+cuda11.6) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DkMLuGDhCR6"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEoRKdmByrb0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb8MBgTOhCR6"
      },
      "source": [
        "### Download the model from Tensorflow Hub\n",
        "\n",
        "Tensorflow Hub is a repository of trained machine learning models which you can reuse in your own projects. \n",
        "- You can see the domains covered [here](https://tfhub.dev/) and its subcategories. \n",
        "- For this lab, you will want to look at the [image object detection subcategory](https://tfhub.dev/s?module-type=image-object-detection). \n",
        "- You can select a model to see more information about it and copy the URL so you can download it to your workspace. \n",
        "- We selected a [inception resnet version 2](https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1)\n",
        "- You can also modify this following cell to choose the other model that we selected, [ssd mobilenet version 2](https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9pCzz4uy20U"
      },
      "source": [
        "# you can switch the commented lines here to pick the other model\n",
        "\n",
        "# inception resnet version 2\n",
        "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
        "\n",
        "# You can choose ssd mobilenet version 2 instead and compare the results\n",
        "#module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3trj5FbhCR6"
      },
      "source": [
        "#### Load the model\n",
        "\n",
        "Next, you'll load the model specified by the `module_handle`.\n",
        "- This will take a few minutes to load the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WHkGDHfhCR6"
      },
      "source": [
        "model = hub.load(module_handle)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ey0FpHGhCR6"
      },
      "source": [
        "#### Choose the default signature\n",
        "\n",
        "Some models in the Tensorflow hub can be used for different tasks. So each model's documentation should show what *signature* to use when running the model. \n",
        "- If you want to see if a model has more than one signature then you can do something like `print(hub.load(module_handle).signatures.keys())`. In your case, the models you will be using only have the `default` signature so you don't have to worry about other types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1BU7AGthCR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790b6770-2d80-4f04-c00c-872e8af1750a"
      },
      "source": [
        "# take a look at the available signatures for this particular model\n",
        "model.signatures.keys()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KeysView(_SignatureMap({'default': <ConcreteFunction pruned(images) at 0x7F5C7C842050>}))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfc9ax9hhCR6"
      },
      "source": [
        "Please choose the 'default' signature for your object detector.\n",
        "- For object detection models, its 'default' signature will accept a batch of image tensors and output a dictionary describing the objects detected, which is what you'll want here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzwR5zE_hCR7"
      },
      "source": [
        "detector = model.signatures['default']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvb-3r3thCR7"
      },
      "source": [
        "### download_and_resize_image\n",
        "\n",
        "This function downloads an image specified by a given \"url\", pre-processes it, and then saves it to disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucsxak_qhCR7"
      },
      "source": [
        "def download_and_resize_image(url, new_width=256, new_height=256):\n",
        "    '''\n",
        "    Fetches an image online, resizes it and saves it locally.\n",
        "    \n",
        "    Args:\n",
        "        url (string) -- link to the image\n",
        "        new_width (int) -- size in pixels used for resizing the width of the image\n",
        "        new_height (int) -- size in pixels used for resizing the length of the image\n",
        "        \n",
        "    Returns:\n",
        "        (string) -- path to the saved image\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    # create a temporary file ending with \".jpg\"\n",
        "    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "    \n",
        "    # opens the given URL\n",
        "    response = urlopen(url)\n",
        "    \n",
        "    # reads the image fetched from the URL\n",
        "    image_data = response.read()\n",
        "    \n",
        "    # puts the image data in memory buffer\n",
        "    image_data = BytesIO(image_data)\n",
        "    \n",
        "    # opens the image\n",
        "    pil_image = Image.open(image_data)\n",
        "    \n",
        "    # resizes the image. will crop if aspect ratio is different.\n",
        "    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "    \n",
        "    # converts to the RGB colorspace\n",
        "    pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "    \n",
        "    # saves the image to the temporary file created earlier\n",
        "    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "    \n",
        "    print(\"Image downloaded to %s.\" % filename)\n",
        "    \n",
        "    return filename"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7qodEJHhCR7"
      },
      "source": [
        "### Download and preprocess an image\n",
        "\n",
        "Now, using `download_and_resize_image` you can get a sample image online and save it locally. \n",
        "- We've provided a URL for you, but feel free to choose another image to run through the object detector.\n",
        "- You can use the original width and height of the image but feel free to modify it and see what results you get."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHTDalVrhCR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6290f1e5-b999-440b-cfb0-05c21359171d"
      },
      "source": [
        "# You can choose a different URL that points to an image of your choice\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/f/fb/20130807_dublin014.JPG\"\n",
        "\n",
        "# download the image and use the original height and width\n",
        "downloaded_image_path = download_and_resize_image(image_url, 3872, 2592)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image downloaded to /tmp/tmpec9a_wym.jpg.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVNXUKMIhCR7"
      },
      "source": [
        "### run_detector\n",
        "\n",
        "This function will take in the object detection model `detector` and the path to a sample image, then use this model to detect objects and display its predicted class categories and detection boxes.\n",
        "- run_detector uses `load_image` to convert the image into a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkkiQzKlhCR7"
      },
      "source": [
        "def load_img(path):\n",
        "    '''\n",
        "    Loads a JPEG image and converts it to a tensor.\n",
        "    \n",
        "    Args:\n",
        "        path (string) -- path to a locally saved JPEG image\n",
        "    \n",
        "    Returns:\n",
        "        (tensor) -- an image tensor\n",
        "    '''\n",
        "    \n",
        "    # read the file\n",
        "    img = tf.io.read_file(path)\n",
        "    \n",
        "    # convert to a tensor\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    \n",
        "    return img\n",
        "\n",
        "\n",
        "def run_detector(detector, path):\n",
        "    '''\n",
        "    Runs inference on a local file using an object detection model.\n",
        "    \n",
        "    Args:\n",
        "        detector (model) -- an object detection model loaded from TF Hub\n",
        "        path (string) -- path to an image saved locally\n",
        "    '''\n",
        "    \n",
        "    # load an image tensor from a local file path\n",
        "    img = load_img(path)\n",
        "\n",
        "    # add a batch dimension in front of the tensor\n",
        "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "    \n",
        "    # run inference using the model\n",
        "    result = detector(converted_img)\n",
        "\n",
        "    # save the results in a dictionary\n",
        "    result = {key:value.numpy() for key,value in result.items()}\n",
        "\n",
        "    # print results\n",
        "    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
        "\n",
        "    print(result[\"detection_scores\"])\n",
        "    print(result[\"detection_class_entities\"])\n",
        "    print(result[\"detection_boxes\"])\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSEeJSkxhCR7"
      },
      "source": [
        "### Run inference on the image\n",
        "\n",
        "You can run your detector by calling the `run_detector` function. This will print the number of objects found followed by three lists: \n",
        "\n",
        "* The detection scores of each object found (i.e. how confident the model is), \n",
        "* The classes of each object found, \n",
        "* The bounding boxes of each object\n",
        "\n",
        "You will see how to overlay this information on the original image in the next sections and in this week's assignment!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csanHvDIz4_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453ad655-1652-4fe4-929c-868f759a8733"
      },
      "source": [
        "# runs the object detection model and prints information about the objects found\n",
        "run_detector(detector, downloaded_image_path)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 objects.\n",
            "[0.6531076  0.61050427 0.6016207  0.59267104 0.5922534  0.58160937\n",
            " 0.5505509  0.49612293 0.47432286 0.47311208 0.44032288 0.4050859\n",
            " 0.39809093 0.39374155 0.37155953 0.36171296 0.3615862  0.34719908\n",
            " 0.33389986 0.3124711  0.28876108 0.25743204 0.25723046 0.25190163\n",
            " 0.24772352 0.23448414 0.20432055 0.20342639 0.17997308 0.17972925\n",
            " 0.17379068 0.16436897 0.16061224 0.1592036  0.15629333 0.15468292\n",
            " 0.14733349 0.13605411 0.12753543 0.12559225 0.12122744 0.11804862\n",
            " 0.11381513 0.11219216 0.11120925 0.09721024 0.09148445 0.08978613\n",
            " 0.08883347 0.08618231 0.08337732 0.08093081 0.07997356 0.07750148\n",
            " 0.07733559 0.07621965 0.07515509 0.07389456 0.07232054 0.07198709\n",
            " 0.07109124 0.06931654 0.06837997 0.06433555 0.06249025 0.0623172\n",
            " 0.06205211 0.05926957 0.05791891 0.05779758 0.05723752 0.05349667\n",
            " 0.05305    0.05222971 0.04899192 0.04818314 0.0458142  0.04412691\n",
            " 0.0434057  0.04290242 0.04265956 0.04166034 0.04086039 0.03967519\n",
            " 0.039628   0.0394058  0.03872345 0.03773912 0.03764757 0.03573024\n",
            " 0.03360288 0.03327466 0.03273812 0.03238463 0.03142019 0.02980406\n",
            " 0.02859709 0.02856457 0.02822559 0.0278959 ]\n",
            "[b'Person' b'Person' b'Person' b'Person' b'Footwear' b'Person' b'Building'\n",
            " b'Bicycle' b'Window' b'Building' b'Person' b'Wheel' b'Building'\n",
            " b'Building' b'Person' b'Wheel' b'Building' b'Window' b'Window'\n",
            " b'Building' b'Person' b'Person' b'Van' b'Bicycle wheel' b'Person'\n",
            " b'Window' b'Window' b'Bicycle' b'Building' b'Window' b'Window' b'Man'\n",
            " b'Person' b'Person' b'Woman' b'Clothing' b'Bicycle wheel' b'Window'\n",
            " b'Person' b'Window' b'Land vehicle' b'Land vehicle' b'Clothing'\n",
            " b'Bicycle' b'Window' b'House' b'Land vehicle' b'Land vehicle' b'House'\n",
            " b'Man' b'Window' b'Clothing' b'Footwear' b'Person' b'Window' b'Man'\n",
            " b'Man' b'House' b'Person' b'Building' b'Clothing' b'Window' b'Person'\n",
            " b'Jeans' b'Man' b'Furniture' b'Person' b'Person' b'Person'\n",
            " b'Land vehicle' b'Person' b'Window' b'House' b'Woman' b'Window' b'Man'\n",
            " b'Person' b'Man' b'Clothing' b'Bicycle' b'Man' b'Person' b'Window'\n",
            " b'Person' b'Car' b'Man' b'Car' b'Chair' b'House' b'Window' b'Clothing'\n",
            " b'Tire' b'Clothing' b'Window' b'Land vehicle' b'Window' b'Man' b'Window'\n",
            " b'Bus' b'Clothing']\n",
            "[[5.1279473e-01 5.2925962e-01 6.0161859e-01 5.5207729e-01]\n",
            " [5.1963103e-01 6.0150892e-01 6.4617193e-01 6.3462472e-01]\n",
            " [5.0551009e-01 5.0044256e-01 6.0129154e-01 5.2308536e-01]\n",
            " [4.8632586e-01 4.1273251e-01 6.7883980e-01 4.5992175e-01]\n",
            " [8.1518954e-01 9.5612621e-01 8.4270734e-01 9.8714703e-01]\n",
            " [4.9540976e-01 9.2354977e-01 8.3567423e-01 9.9905038e-01]\n",
            " [1.1511180e-02 1.2247683e-02 7.3855674e-01 4.2466375e-01]\n",
            " [5.7767230e-01 3.6645705e-01 7.1276760e-01 4.8336887e-01]\n",
            " [0.0000000e+00 1.1926064e-01 2.2389247e-01 1.8393019e-01]\n",
            " [7.7411778e-02 4.1301334e-01 5.7954133e-01 5.6044757e-01]\n",
            " [5.1382101e-01 7.4802995e-01 5.9199351e-01 7.6661122e-01]\n",
            " [6.3213921e-01 3.5992417e-01 7.0386893e-01 4.1182488e-01]\n",
            " [0.0000000e+00 7.9702795e-01 6.7339528e-01 1.0000000e+00]\n",
            " [1.6031241e-02 6.8488276e-01 5.5876786e-01 8.1117457e-01]\n",
            " [5.0028229e-01 3.7696537e-01 6.3325584e-01 4.1450077e-01]\n",
            " [6.4053279e-01 4.4508958e-01 7.0298266e-01 4.8343948e-01]\n",
            " [0.0000000e+00 2.1901983e-01 6.6035432e-01 4.3327850e-01]\n",
            " [1.9339562e-03 0.0000000e+00 1.3937531e-01 2.6295612e-02]\n",
            " [2.5770443e-03 9.6666551e-01 1.5372506e-01 1.0000000e+00]\n",
            " [5.7858787e-04 1.5115313e-03 7.6518577e-01 2.6995319e-01]\n",
            " [5.0452137e-01 3.6118668e-01 6.3472915e-01 3.8534448e-01]\n",
            " [4.9806300e-01 3.6457533e-01 6.6122484e-01 4.0497488e-01]\n",
            " [4.8340294e-01 6.1965936e-01 5.6270558e-01 6.6155607e-01]\n",
            " [6.3127923e-01 3.6036405e-01 7.0415395e-01 4.1149774e-01]\n",
            " [5.2181751e-01 5.7764828e-01 5.8759820e-01 6.0071927e-01]\n",
            " [2.1957055e-01 3.4874532e-01 3.3837628e-01 3.7707776e-01]\n",
            " [1.2486146e-01 2.5091079e-01 2.7992788e-01 2.8158110e-01]\n",
            " [5.7717192e-01 3.6229616e-01 7.0702648e-01 4.4184664e-01]\n",
            " [2.5748560e-01 5.6756794e-01 5.3107476e-01 6.8773562e-01]\n",
            " [4.2056929e-02 8.7477028e-01 2.5277409e-01 9.1302925e-01]\n",
            " [1.5635246e-01 4.4339925e-01 2.2220708e-01 4.7578439e-01]\n",
            " [5.0196582e-01 9.2148894e-01 8.3638638e-01 1.0000000e+00]\n",
            " [5.2361524e-01 5.7025254e-01 5.8451873e-01 5.9157968e-01]\n",
            " [5.1324499e-01 6.7927116e-01 5.5099100e-01 6.9258082e-01]\n",
            " [5.1911950e-01 5.9998173e-01 6.4637798e-01 6.3403529e-01]\n",
            " [5.2430898e-01 9.2496032e-01 8.1075472e-01 9.9799871e-01]\n",
            " [6.3819188e-01 4.4292125e-01 7.0165384e-01 4.8409477e-01]\n",
            " [3.4220602e-02 3.5557657e-01 1.6225289e-01 3.7492302e-01]\n",
            " [4.8845527e-01 4.5348868e-01 6.2180793e-01 4.7972515e-01]\n",
            " [9.2970213e-04 3.0770037e-01 1.0652386e-01 3.3205810e-01]\n",
            " [4.8301089e-01 6.1991566e-01 5.6477886e-01 6.6069531e-01]\n",
            " [5.8219850e-01 3.6493590e-01 7.1387506e-01 4.8469716e-01]\n",
            " [5.2355427e-01 7.4920201e-01 5.8538091e-01 7.6531953e-01]\n",
            " [6.0915411e-01 4.2671743e-01 7.0516211e-01 4.8708999e-01]\n",
            " [3.5136688e-01 9.7485697e-01 5.5313450e-01 9.9887550e-01]\n",
            " [0.0000000e+00 8.1119698e-01 6.8640810e-01 9.9715137e-01]\n",
            " [5.7628351e-01 3.5746214e-01 7.0481360e-01 4.4031671e-01]\n",
            " [5.6487918e-01 3.6302269e-01 7.0865870e-01 4.1603777e-01]\n",
            " [1.0943273e-02 2.3339069e-02 7.2640151e-01 4.2175424e-01]\n",
            " [4.8468190e-01 4.1069093e-01 6.9466919e-01 4.6309370e-01]\n",
            " [8.0973707e-02 3.8470858e-01 2.0781180e-01 4.1174710e-01]\n",
            " [5.3828692e-01 6.0357070e-01 6.3477248e-01 6.3440746e-01]\n",
            " [6.2984246e-01 6.1497778e-01 6.4493269e-01 6.2538809e-01]\n",
            " [5.0274915e-01 3.8238895e-01 5.9613478e-01 4.1272396e-01]\n",
            " [0.0000000e+00 1.2453129e-02 1.4019854e-01 2.4740605e-02]\n",
            " [5.1444054e-01 7.4778980e-01 5.9198588e-01 7.6682734e-01]\n",
            " [5.0618082e-01 5.0040841e-01 6.0068381e-01 5.2331388e-01]\n",
            " [0.0000000e+00 2.1127144e-01 6.5080416e-01 4.3429139e-01]\n",
            " [4.8944759e-01 4.5438790e-01 5.7236749e-01 4.7647089e-01]\n",
            " [0.0000000e+00 7.0621765e-01 6.1699915e-01 8.6625129e-01]\n",
            " [5.0917399e-01 4.1628113e-01 6.6930115e-01 4.5959792e-01]\n",
            " [4.6521188e-03 8.0309325e-01 1.5984620e-01 8.4039801e-01]\n",
            " [5.2613920e-01 5.6835097e-01 5.7944065e-01 5.8281320e-01]\n",
            " [6.7192793e-01 9.4027972e-01 8.2127810e-01 9.8925090e-01]\n",
            " [5.0276846e-01 3.7387595e-01 6.4697206e-01 4.1297135e-01]\n",
            " [5.7423753e-01 2.6739421e-01 6.5777165e-01 3.2031906e-01]\n",
            " [4.8604447e-01 4.4450867e-01 6.2479347e-01 4.7350609e-01]\n",
            " [5.1724863e-01 7.5697178e-01 5.8851451e-01 7.7146727e-01]\n",
            " [5.2337217e-01 5.5784953e-01 5.7913721e-01 5.7354069e-01]\n",
            " [6.1246103e-01 4.2734414e-01 7.0607221e-01 4.8825231e-01]\n",
            " [5.2412355e-01 5.6155121e-01 5.7838053e-01 5.8047241e-01]\n",
            " [0.0000000e+00 2.4422672e-01 6.0780287e-02 2.9361784e-01]\n",
            " [1.4872411e-02 2.1368947e-03 7.4541229e-01 2.5976312e-01]\n",
            " [4.9324220e-01 9.2394942e-01 8.3708733e-01 9.9775493e-01]\n",
            " [8.3684092e-03 2.4216488e-01 4.9730100e-02 2.8315970e-01]\n",
            " [5.0532430e-01 3.6017197e-01 6.4355981e-01 3.9146832e-01]\n",
            " [5.1310647e-01 5.2379507e-01 6.0050929e-01 5.4297292e-01]\n",
            " [5.2041841e-01 6.0097468e-01 6.4613068e-01 6.3436699e-01]\n",
            " [5.1822031e-01 5.0339061e-01 5.9754801e-01 5.2268147e-01]\n",
            " [5.9417248e-01 3.6132768e-01 7.0545769e-01 4.1585889e-01]\n",
            " [5.1325583e-01 6.7931157e-01 5.5053020e-01 6.9248211e-01]\n",
            " [5.2230167e-01 5.3619468e-01 5.9756422e-01 5.5316162e-01]\n",
            " [4.2987627e-01 8.2870173e-01 5.8991992e-01 8.6432201e-01]\n",
            " [5.0487775e-01 3.8941649e-01 6.1507374e-01 4.1993615e-01]\n",
            " [5.2658528e-01 6.2716925e-01 5.6329966e-01 6.5372539e-01]\n",
            " [5.0129867e-01 3.6418670e-01 6.5994704e-01 4.0379608e-01]\n",
            " [5.1512820e-01 6.2409008e-01 5.6379408e-01 6.5800601e-01]\n",
            " [5.7313722e-01 2.6689947e-01 6.6616708e-01 3.1863943e-01]\n",
            " [8.3400726e-02 4.0741983e-01 5.8408278e-01 5.5851340e-01]\n",
            " [2.8819725e-01 4.7552801e-04 4.1436085e-01 3.6601342e-02]\n",
            " [4.9727160e-01 4.5529070e-01 5.8382219e-01 4.7793597e-01]\n",
            " [6.2716651e-01 3.6102504e-01 7.0599329e-01 4.0977982e-01]\n",
            " [5.1586109e-01 3.8005272e-01 5.9690225e-01 4.1175565e-01]\n",
            " [1.1805163e-02 3.0812868e-01 9.7291172e-02 3.2503814e-01]\n",
            " [5.1245582e-01 6.2363499e-01 5.6242347e-01 6.5764558e-01]\n",
            " [4.0099874e-01 8.8509369e-01 5.8127278e-01 9.3921930e-01]\n",
            " [5.1385814e-01 5.2948540e-01 6.0200483e-01 5.5236262e-01]\n",
            " [0.0000000e+00 1.0066434e-02 1.3616100e-01 3.1600505e-02]\n",
            " [4.8042899e-01 6.2042850e-01 5.6528729e-01 6.6014701e-01]\n",
            " [5.1935816e-01 3.6183944e-01 6.2499619e-01 3.8492191e-01]]\n"
          ]
        }
      ]
    }
  ]
}