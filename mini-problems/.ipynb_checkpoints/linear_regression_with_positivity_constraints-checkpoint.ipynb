{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lingchm/datascience/blob/master/exercises/socially_distanced_robots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVWkxKm9TYyT"
   },
   "source": [
    "# Linear Regression with Positivity Constraints\n",
    "\n",
    "*Convex optimization*, *Projected gradient descent*, *primal-dual algorithm*\n",
    "\n",
    "**Problem**\n",
    "\n",
    "Given the least squares with positivity constraints:\n",
    "\\begin{equation}\n",
    "\\min_{x \\in \\mathbb{R}^N} \\frac{1}{2} ||y-Ax||_2^2 \\: \\: \\: \\text{s.t.} x \\geq 0,\n",
    "\\end{equation}\n",
    "where $A \\in \\mathbb{R}^{MxN}$ and assume $rank(A) = N$.\n",
    "\n",
    "This is natural in many practical applications where the entries of $x$ do not make sense where they are negative (e.g., light intensity, concentration of some physical material, etc.). \n",
    "\n",
    "**Method**\n",
    "\n",
    "We explore three alternative approaches for solving this problem. \n",
    "1. One way is to write the Lagrangian function and directly solve the problem. \n",
    "2. Another way is using projected gradient descent. \n",
    "3. A third way is using the primal-dual approach, which avoids having to worry about step sizes. \n",
    "\n",
    "We implement all three algorithms below. \n",
    "\n",
    "**References**\n",
    "\n",
    "Credits to Dr. Justin Romberg for designing this problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "naVMsakRO7je"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cvxpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f09751e7ea87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcvxpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cvxpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "osBCIqX-Ztvh"
   },
   "outputs": [],
   "source": [
    "# Create data\n",
    "m = 30\n",
    "n = 10\n",
    "np.random.seed(20212)\n",
    "A = np.random.randn(m, n)\n",
    "y = np.random.randn(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: CVXPT\n",
    "x = cp.Variable(n)\n",
    "objective = cp.Minimize(0.5*cp.norm(A@x - y,2)**2)\n",
    "constraints = [0 <= x]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "result = prob.solve()\n",
    "xstar = x.value\n",
    "lambdastar = constraints[0].dual_value\n",
    "    \n",
    "# verify optimality condition\n",
    "print(A.T @ A @ xstar - A.T @ y - lambdastar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xBikm2tiZw_e"
   },
   "outputs": [],
   "source": [
    "# Solution 2: probjected gradient descent\n",
    "def obj_function(A, x, y):\n",
    "    return 0.5*np.linalg.norm(y - A @ x)**2\n",
    "    \n",
    "def gradf(A, x, y):\n",
    "    return A.T @ A @ x - A.T @ y \n",
    "\n",
    "def prox(z):\n",
    "    z[np.where(z < 0)] = 0\n",
    "    return z\n",
    "    \n",
    "def projectedGD(x0, A, y, alpha=0.001, tol=1e-6, max_iter=10000):\n",
    "    k, xk, xk_, ak = 0, x0, x0+1, alpha\n",
    "    while np.linalg.norm(xk_ - xk) > tol and k < max_iter:\n",
    "        # gradient step\n",
    "        dk = -gradf(A, xk, y) \n",
    "        # projection step \n",
    "        xk_ = xk*1\n",
    "        xk = prox(xk + ak * dk)\n",
    "        k += 1\n",
    "    print(\"Number of iterations of gradient descent:\", k)\n",
    "    print(\"Estimated x:\", xk)\n",
    "    return xk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.009669807351846\n",
      "Number of iterations of gradient descent: 505\n",
      "Estimated x: [0.         0.02932242 0.         0.         0.0357236  0.\n",
      " 0.         0.         0.32954082 0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.02932242, 0.        , 0.        , 0.0357236 ,\n",
       "       0.        , 0.        , 0.        , 0.32954082, 0.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.linalg.norm(1/ (A.T @ A)))\n",
    "projectedGD(np.zeros(n), A, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "ioNaT09mZ2n-",
    "outputId": "03e8cc5d-484c-4a63-81c9-a407e3849eeb"
   },
   "outputs": [],
   "source": [
    "# Solution 3: primal-dual\n",
    "def primaldual(x0, A, y, tol=1e-6, max_iter=1000):\n",
    "    k, xk, xk_, lmbda = 0, x0, x0+1, x0+1\n",
    "    while np.linalg.norm(xk_ - xk) > tol and k < max_iter:\n",
    "        # primal\n",
    "        xk_ = xk*1\n",
    "        xk = np.linalg.inv(A.T @ A) @ (A.T @ y + lmbda)\n",
    "        xk = prox(xk)\n",
    "        # dual\n",
    "        lmbda = (A.T @ A @ xk - A.T @ y)\n",
    "        lmbda = prox(lmbda)\n",
    "        # check complementary slackness\n",
    "        lmbda[np.where(xk > tol)] = 0\n",
    "        k += 1\n",
    "    print(\"Number of iterations of gradient descent:\", k)\n",
    "    print(\"Estimated x:\", xk)\n",
    "    return xk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations of gradient descent: 1000\n",
      "Estimated x: [2.68960998e+55 0.00000000e+00 5.24503831e+54 0.00000000e+00\n",
      " 4.79619276e+54 0.00000000e+00 4.13017869e+55 1.84109759e+55\n",
      " 2.38295296e+55 0.00000000e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.68960998e+55, 0.00000000e+00, 5.24503831e+54, 0.00000000e+00,\n",
       "       4.79619276e+54, 0.00000000e+00, 4.13017869e+55, 1.84109759e+55,\n",
       "       2.38295296e+55, 0.00000000e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primaldual(np.zeros(n), A, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOTOc1U71AUuA5lNSIVuRuz",
   "include_colab_link": true,
   "name": "socially_distanced_robots.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
